{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"background-color: #2b2c4f; padding: 10px; border-radius: 5px; border: 1px solid #b3d9ff; color: #ffffff;\">\n",
        "<h1>NOTE:</h1>\n",
        "<h3>This notebook is a modified version of the original notebook provided by the instructor.<br></h3>\n",
        "<h3>I have added my own comments and explanations to the code.<br></h3>\n",
        "<h3>I have also added my own code to the notebook to complete the assignment at the end.<br></h3>\n",
        "<h3>Please use git lfs as I have added a large file to the repository.<br></h3>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lElF3o5PR6ys"
      },
      "source": [
        "# Your First RAG Application\n",
        "\n",
        "In this notebook, we'll walk you through each of the components that are involved in a simple RAG application.\n",
        "\n",
        "We won't be leveraging any fancy tools, just the OpenAI Python SDK, Numpy, and some classic Python.\n",
        "\n",
        "> NOTE: This was done with Python 3.11.4.\n",
        "\n",
        "> NOTE: There might be [compatibility issues](https://github.com/wandb/wandb/issues/7683) if you're on NVIDIA driver >552.44 As an interim solution - you can rollback your drivers to the 552.44.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CtcL8P8R6yt"
      },
      "source": [
        "## Table of Contents:\n",
        "\n",
        "- Task 1: Imports and Utilities\n",
        "- Task 2: Documents\n",
        "- Task 3: Embeddings and Vectors\n",
        "- Task 4: Prompts\n",
        "- Task 5: Retrieval Augmented Generation\n",
        "  - 🚧 Activity #1: Augment RAG\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Dz6GYilR6yt"
      },
      "source": [
        "Let's look at a rather complicated looking visual representation of a basic RAG application.\n",
        "\n",
        "<img src=\"https://i.imgur.com/vD8b016.png\" />\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjmC0KFtR6yt"
      },
      "source": [
        "## Task 1: Imports and Utility\n",
        "\n",
        "We're just doing some imports and enabling `async` to work within the Jupyter environment here, nothing too crazy!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Z1dyrG4hR6yt"
      },
      "outputs": [],
      "source": [
        "from aimakerspace.text_utils import TextFileLoader, CharacterTextSplitter\n",
        "from aimakerspace.vectordatabase import VectorDatabase\n",
        "import asyncio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9OrFZRnER6yt"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0jGnpQsR6yu"
      },
      "source": [
        "## Task 2: Documents\n",
        "\n",
        "We'll be concerning ourselves with this part of the flow in the following section:\n",
        "\n",
        "<img src=\"https://i.imgur.com/jTm9gjk.png\" />\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SFPWvRUR6yu"
      },
      "source": [
        "### Loading Source Documents\n",
        "\n",
        "So, first things first, we need some documents to work with.\n",
        "\n",
        "While we could work directly with the `.txt` files (or whatever file-types you wanted to extend this to) we can instead do some batch processing of those documents at the beginning in order to store them in a more machine compatible format.\n",
        "\n",
        "In this case, we're going to parse our text file into a single document in memory.\n",
        "\n",
        "Let's look at the relevant bits of the `TextFileLoader` class:\n",
        "\n",
        "```python\n",
        "def load_file(self):\n",
        "        with open(self.path, \"r\", encoding=self.encoding) as f:\n",
        "            self.documents.append(f.read())\n",
        "```\n",
        "\n",
        "We're simply loading the document using the built in `open` method, and storing that output in our `self.documents` list.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ia2sUEuGR6yu",
        "outputId": "84937ecc-c35f-4c4a-a4ab-9da72625954c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_loader = TextFileLoader(\"data/PMarcaBlogs.txt\")\n",
        "documents = text_loader.load_documents()\n",
        "len(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bV-tj5WFR6yu",
        "outputId": "674eb315-1ff3-4597-bcf5-38ece0a812ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "The Pmarca Blog Archives\n",
            "(select posts from 2007-2009)\n",
            "Marc Andreessen\n",
            "copyright: Andreessen Horow\n"
          ]
        }
      ],
      "source": [
        "print(documents[0][:100])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHlTvCzYR6yu"
      },
      "source": [
        "### Splitting Text Into Chunks\n",
        "\n",
        "As we can see, there is one massive document.\n",
        "\n",
        "We'll want to chunk the document into smaller parts so it's easier to pass the most relevant snippets to the LLM.\n",
        "\n",
        "There is no fixed way to split/chunk documents - and you'll need to rely on some intuition as well as knowing your data _very_ well in order to build the most robust system.\n",
        "\n",
        "For this toy example, we'll just split blindly on length.\n",
        "\n",
        "> There's an opportunity to clear up some terminology here, for this course we will be stick to the following:\n",
        ">\n",
        "> - \"source documents\" : The `.txt`, `.pdf`, `.html`, ..., files that make up the files and information we start with in its raw format\n",
        "> - \"document(s)\" : single (or more) text object(s)\n",
        "> - \"corpus\" : the combination of all of our documents\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2G6Voc0jR6yv"
      },
      "source": [
        "As you can imagine (though it's not specifically true in this toy example) the idea of splitting documents is to break them into managable sized chunks that retain the most relevant local context.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMC4tsEmR6yv",
        "outputId": "08689c0b-57cd-4040-942a-8193e997f5cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "373"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_splitter = CharacterTextSplitter()\n",
        "split_documents = text_splitter.split_texts(documents)\n",
        "len(split_documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2wKT0WLR6yv"
      },
      "source": [
        "Let's take a look at some of the documents we've managed to split.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcYMwWJoR6yv",
        "outputId": "20d69876-feca-4826-b4be-32915276987a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['\\ufeff\\nThe Pmarca Blog Archives\\n(select posts from 2007-2009)\\nMarc Andreessen\\ncopyright: Andreessen Horowitz\\ncover design: Jessica Hagy\\nproduced using: Pressbooks\\nContents\\nTHE PMARCA GUIDE TO STARTUPS\\nPart 1: Why not to do a startup 2\\nPart 2: When the VCs say \"no\" 10\\nPart 3: \"But I don\\'t know any VCs!\" 18\\nPart 4: The only thing that matters 25\\nPart 5: The Moby Dick theory of big companies 33\\nPart 6: How much funding is too little? Too much? 41\\nPart 7: Why a startup\\'s initial business plan doesn\\'t\\nmatter that much\\n49\\nTHE PMARCA GUIDE TO HIRING\\nPart 8: Hiring, managing, promoting, and Dring\\nexecutives\\n54\\nPart 9: How to hire a professional CEO 68\\nHow to hire the best people you\\'ve ever worked\\nwith\\n69\\nTHE PMARCA GUIDE TO BIG COMPANIES\\nPart 1: Turnaround! 82\\nPart 2: Retaining great people 86\\nTHE PMARCA GUIDE TO CAREER, PRODUCTIVITY,\\nAND SOME OTHER THINGS\\nIntroduction 97\\nPart 1: Opportunity 99\\nPart 2: Skills and education 107\\nPart 3: Where to go and why 120\\nThe Pmarca Guide to Personal Productivi']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "split_documents[0:1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOU-RFP_R6yv"
      },
      "source": [
        "## Task 3: Embeddings and Vectors\n",
        "\n",
        "Next, we have to convert our corpus into a \"machine readable\" format as we explored in the Embedding Primer notebook.\n",
        "\n",
        "Today, we're going to talk about the actual process of creating, and then storing, these embeddings, and how we can leverage that to intelligently add context to our queries.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### OpenAI API Key\n",
        "\n",
        "In order to access OpenAI's APIs, we'll need to provide our OpenAI API Key!\n",
        "\n",
        "You can work through the folder \"OpenAI API Key Setup\" for more information on this process if you don't already have an API Key!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "from getpass import getpass\n",
        "\n",
        "openai.api_key = getpass(\"OpenAI API Key: \")\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai.api_key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Vector Database\n",
        "\n",
        "Let's set up our vector database to hold all our documents and their embeddings!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDQrfAR1R6yv"
      },
      "source": [
        "While this is all baked into 1 call - we can look at some of the code that powers this process to get a better understanding:\n",
        "\n",
        "Let's look at our `VectorDatabase().__init__()`:\n",
        "\n",
        "```python\n",
        "def __init__(self, embedding_model: EmbeddingModel = None):\n",
        "        self.vectors = defaultdict(np.array)\n",
        "        self.embedding_model = embedding_model or EmbeddingModel()\n",
        "```\n",
        "\n",
        "As you can see - our vectors are merely stored as a dictionary of `np.array` objects.\n",
        "\n",
        "Secondly, our `VectorDatabase()` has a default `EmbeddingModel()` which is a wrapper for OpenAI's `text-embedding-3-small` model.\n",
        "\n",
        "> **Quick Info About `text-embedding-3-small`**:\n",
        ">\n",
        "> - It has a context window of **8191** tokens\n",
        "> - It returns vectors with dimension **1536**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L273pRdeR6yv"
      },
      "source": [
        "#### ❓Question #1:\n",
        "\n",
        "The default embedding dimension of `text-embedding-3-small` is 1536, as noted above.\n",
        "\n",
        "1. Is there any way to modify this dimension?\n",
        "2. What technique does OpenAI use to achieve this?\n",
        "\n",
        "> NOTE: Check out this [API documentation](https://platform.openai.com/docs/api-reference/embeddings/create) for the answer to question #1, and [this documentation](https://platform.openai.com/docs/guides/embeddings/use-cases) for an answer to question #2!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"background-color: #2b2c4f; padding: 10px; border-radius: 5px; border: 1px solid #b3d9ff; color: #fff;\">\n",
        "### &#x2611; Answer\n",
        "\n",
        "1. No, the dimension cannot be modified directly. However, we can use dimensionality reduction techniques to reduce the dimension of the embeddings. Ex: PCA, SVD, t-SNE, etc. Also we can use clustering techniques to reduce the dimension of the embeddings. Ex: K-Means, DBSCAN, etc. Additionally we can pass a custom dimension to the embedding model.\n",
        "\n",
        "2. OpenAI uses a technique called \"dimensionality reduction\" to achieve this. Ex: PCA, SVD, t-SNE, etc.\n",
        "\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5FZY7K3R6yv"
      },
      "source": [
        "We can call the `async_get_embeddings` method of our `EmbeddingModel()` on a list of `str` and receive a list of `float` back!\n",
        "\n",
        "```python\n",
        "async def async_get_embeddings(self, list_of_text: List[str]) -> List[List[float]]:\n",
        "        return await aget_embeddings(\n",
        "            list_of_text=list_of_text, engine=self.embeddings_model_name\n",
        "        )\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSct6X0aR6yv"
      },
      "source": [
        "We cast those to `np.array` when we build our `VectorDatabase()`:\n",
        "\n",
        "```python\n",
        "async def abuild_from_list(self, list_of_text: List[str]) -> \"VectorDatabase\":\n",
        "        embeddings = await self.embedding_model.async_get_embeddings(list_of_text)\n",
        "        for text, embedding in zip(list_of_text, embeddings):\n",
        "            self.insert(text, np.array(embedding))\n",
        "        return self\n",
        "```\n",
        "\n",
        "And that's all we need to do!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "O4KoLbVDR6yv"
      },
      "outputs": [],
      "source": [
        "vector_db = VectorDatabase()\n",
        "vector_db = asyncio.run(vector_db.abuild_from_list(split_documents))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSZwaGvpR6yv"
      },
      "source": [
        "#### ❓Question #2:\n",
        "\n",
        "What are the benefits of using an `async` approach to collecting our embeddings?\n",
        "\n",
        "> NOTE: Determining the core difference between `async` and `sync` will be useful! If you get stuck - ask ChatGPT!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"background-color: #2b2c4f; padding: 10px; border-radius: 5px; border: 1px solid #b3d9ff; color: #fff;\">\n",
        "\n",
        "### &#x2611; Answer\n",
        "\n",
        "1. Async approach is more efficient and faster as it allows for concurrent execution of the embedding process.\n",
        "2. Async approach is more scalable and can handle more requests per second.\n",
        "3. Async approach is more robust and can handle failures gracefully.\n",
        "\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRBdIt-xR6yw"
      },
      "source": [
        "So, to review what we've done so far in natural language:\n",
        "\n",
        "1. We load source documents\n",
        "2. We split those source documents into smaller chunks (documents)\n",
        "3. We send each of those documents to the `text-embedding-3-small` OpenAI API endpoint\n",
        "4. We store each of the text representations with the vector representations as keys/values in a dictionary\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-vWANZyR6yw"
      },
      "source": [
        "### Semantic Similarity\n",
        "\n",
        "The next step is to be able to query our `VectorDatabase()` with a `str` and have it return to us vectors and text that is most relevant from our corpus.\n",
        "\n",
        "We're going to use the following process to achieve this in our toy example:\n",
        "\n",
        "1. We need to embed our query with the same `EmbeddingModel()` as we used to construct our `VectorDatabase()`\n",
        "2. We loop through every vector in our `VectorDatabase()` and use a distance measure to compare how related they are\n",
        "3. We return a list of the top `k` closest vectors, with their text representations\n",
        "\n",
        "There's some very heavy optimization that can be done at each of these steps - but let's just focus on the basic pattern in this notebook.\n",
        "\n",
        "> We are using [cosine similarity](https://www.engati.com/glossary/cosine-similarity) as a distance metric in this example - but there are many many distance metrics you could use - like [these](https://flavien-vidal.medium.com/similarity-distances-for-natural-language-processing-16f63cd5ba55)\n",
        "\n",
        "> We are using a rather inefficient way of calculating relative distance between the query vector and all other vectors - there are more advanced approaches that are much more efficient, like [ANN](https://towardsdatascience.com/comprehensive-guide-to-approximate-nearest-neighbors-algorithms-8b94f057d6b6)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76d96uavR6yw",
        "outputId": "bbfccc31-20a2-41c7-c14d-46554a43ed2d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('ordingly.\\nSeventh, when hiring the executive to run your former specialty, be\\ncareful you don’t hire someone weak on purpose.\\nThis sounds silly, but you wouldn’t believe how oaen it happens.\\nThe CEO who used to be a product manager who has a weak\\nproduct management executive. The CEO who used to be in\\nsales who has a weak sales executive. The CEO who used to be\\nin marketing who has a weak marketing executive.\\nI call this the “Michael Eisner Memorial Weak Executive Problem” — aaer the CEO of Disney who had previously been a brilliant TV network executive. When he bought ABC at Disney, it\\npromptly fell to fourth place. His response? “If I had an extra\\ntwo days a week, I could turn around ABC myself.” Well, guess\\nwhat, he didn’t have an extra two days a week.\\nA CEO — or a startup founder — oaen has a hard time letting\\ngo of the function that brought him to the party. The result: you\\nhire someone weak into the executive role for that function so\\nthat you can continue to be “the man” — cons',\n",
              "  0.6538563767462549),\n",
              " ('m. They have areas where they are truly deXcient in judgment or skill set. That’s just life. Almost nobody is brilliant\\nat everything. When hiring and when Hring executives, you\\nmust therefore focus on strength rather than lack of weakness. Everybody has severe weaknesses even if you can’t see\\nthem yet. When managing, it’s oaen useful to micromanage and\\nto provide remedial training around these weaknesses. Doing so\\nmay make the diWerence between an executive succeeding or\\nfailing.\\nFor example, you might have a brilliant engineering executive\\nwho generates excellent team loyalty, has terriXc product judgment and makes the trains run on time. This same executive\\nmay be very poor at relating to the other functions in the company. She may generate far more than her share of cross-functional conYicts, cut herself oW from critical information, and\\nsigniXcantly impede your ability to sell and market eWectively.\\nYour alternatives are:\\n(a) Macro-manage and give her an annual or quarterly object',\n",
              "  0.5036012174947994),\n",
              " ('ed?\\nIn reality — as opposed to Marc’s warped view of reality — it will\\nbe extremely helpful for Marc [if he were actually the CEO,\\nwhich he is not] to meet with the new head of engineering daily\\nwhen she comes on board and review all of her thinking and\\ndecisions. This level of micromanagement will accelerate her\\ntraining and improve her long-term eWectiveness. It will make\\nher seem smarter to the rest of the organization which will build\\ncredibility and conXdence while she comes up to speed. Micromanaging new executives is generally a good idea for a limited\\nperiod of time.\\nHowever, that is not the only time that it makes sense to micro66 The Pmarca Blog Archives\\nmanage executives. It turns out that just about every executive\\nin the world has a few things that are seriously wrong with\\nthem. They have areas where they are truly deXcient in judgment or skill set. That’s just life. Almost nobody is brilliant\\nat everything. When hiring and when Hring executives, you\\nmust therefore focus o',\n",
              "  0.481410259497753)]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vector_db.search_by_text(\"What is the Michael Eisner Memorial Weak Executive Problem?\", k=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TehsfIiKR6yw"
      },
      "source": [
        "## Task 4: Prompts\n",
        "\n",
        "In the following section, we'll be looking at the role of prompts - and how they help us to guide our application in the right direction.\n",
        "\n",
        "In this notebook, we're going to rely on the idea of \"zero-shot in-context learning\".\n",
        "\n",
        "This is a lot of words to say: \"We will ask it to perform our desired task in the prompt, and provide no examples.\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXpA0UveR6yw"
      },
      "source": [
        "### XYZRolePrompt\n",
        "\n",
        "Before we do that, let's stop and think a bit about how OpenAI's chat models work.\n",
        "\n",
        "We know they have roles - as is indicated in the following API [documentation](https://platform.openai.com/docs/api-reference/chat/create#chat/create-messages)\n",
        "\n",
        "There are three roles, and they function as follows (taken directly from [OpenAI](https://platform.openai.com/docs/guides/gpt/chat-completions-api)):\n",
        "\n",
        "- `{\"role\" : \"system\"}` : The system message helps set the behavior of the assistant. For example, you can modify the personality of the assistant or provide specific instructions about how it should behave throughout the conversation. However note that the system message is optional and the model’s behavior without a system message is likely to be similar to using a generic message such as \"You are a helpful assistant.\"\n",
        "- `{\"role\" : \"user\"}` : The user messages provide requests or comments for the assistant to respond to.\n",
        "- `{\"role\" : \"assistant\"}` : Assistant messages store previous assistant responses, but can also be written by you to give examples of desired behavior.\n",
        "\n",
        "The main idea is this:\n",
        "\n",
        "1. You start with a system message that outlines how the LLM should respond, what kind of behaviours you can expect from it, and more\n",
        "2. Then, you can provide a few examples in the form of \"assistant\"/\"user\" pairs\n",
        "3. Then, you prompt the model with the true \"user\" message.\n",
        "\n",
        "In this example, we'll be forgoing the 2nd step for simplicities sake.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdZ2KWKSR6yw"
      },
      "source": [
        "#### Utility Functions\n",
        "\n",
        "You'll notice that we're using some utility functions from the `aimakerspace` module - let's take a peek at these and see what they're doing!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFbeJDDsR6yw"
      },
      "source": [
        "##### XYZRolePrompt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mojJSE3R6yw"
      },
      "source": [
        "Here we have our `system`, `user`, and `assistant` role prompts.\n",
        "\n",
        "Let's take a peek at what they look like:\n",
        "\n",
        "```python\n",
        "class BasePrompt:\n",
        "    def __init__(self, prompt):\n",
        "        \"\"\"\n",
        "        Initializes the BasePrompt object with a prompt template.\n",
        "\n",
        "        :param prompt: A string that can contain placeholders within curly braces\n",
        "        \"\"\"\n",
        "        self.prompt = prompt\n",
        "        self._pattern = re.compile(r\"\\{([^}]+)\\}\")\n",
        "\n",
        "    def format_prompt(self, **kwargs):\n",
        "        \"\"\"\n",
        "        Formats the prompt string using the keyword arguments provided.\n",
        "\n",
        "        :param kwargs: The values to substitute into the prompt string\n",
        "        :return: The formatted prompt string\n",
        "        \"\"\"\n",
        "        matches = self._pattern.findall(self.prompt)\n",
        "        return self.prompt.format(**{match: kwargs.get(match, \"\") for match in matches})\n",
        "\n",
        "    def get_input_variables(self):\n",
        "        \"\"\"\n",
        "        Gets the list of input variable names from the prompt string.\n",
        "\n",
        "        :return: List of input variable names\n",
        "        \"\"\"\n",
        "        return self._pattern.findall(self.prompt)\n",
        "```\n",
        "\n",
        "Then we have our `RolePrompt` which laser focuses us on the role pattern found in most API endpoints for LLMs.\n",
        "\n",
        "```python\n",
        "class RolePrompt(BasePrompt):\n",
        "    def __init__(self, prompt, role: str):\n",
        "        \"\"\"\n",
        "        Initializes the RolePrompt object with a prompt template and a role.\n",
        "\n",
        "        :param prompt: A string that can contain placeholders within curly braces\n",
        "        :param role: The role for the message ('system', 'user', or 'assistant')\n",
        "        \"\"\"\n",
        "        super().__init__(prompt)\n",
        "        self.role = role\n",
        "\n",
        "    def create_message(self, **kwargs):\n",
        "        \"\"\"\n",
        "        Creates a message dictionary with a role and a formatted message.\n",
        "\n",
        "        :param kwargs: The values to substitute into the prompt string\n",
        "        :return: Dictionary containing the role and the formatted message\n",
        "        \"\"\"\n",
        "        return {\"role\": self.role, \"content\": self.format_prompt(**kwargs)}\n",
        "```\n",
        "\n",
        "We'll look at how the `SystemRolePrompt` is constructed to get a better idea of how that extension works:\n",
        "\n",
        "```python\n",
        "class SystemRolePrompt(RolePrompt):\n",
        "    def __init__(self, prompt: str):\n",
        "        super().__init__(prompt, \"system\")\n",
        "```\n",
        "\n",
        "That pattern is repeated for our `UserRolePrompt` and our `AssistantRolePrompt` as well.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D361R6sMR6yw"
      },
      "source": [
        "##### ChatOpenAI\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJVQ2Pm8R6yw"
      },
      "source": [
        "Next we have our model, which is converted to a format analagous to libraries like LangChain and LlamaIndex.\n",
        "\n",
        "Let's take a peek at how that is constructed:\n",
        "\n",
        "```python\n",
        "class ChatOpenAI:\n",
        "    def __init__(self, model_name: str = \"gpt-4o-mini\"):\n",
        "        self.model_name = model_name\n",
        "        self.openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "        if self.openai_api_key is None:\n",
        "            raise ValueError(\"OPENAI_API_KEY is not set\")\n",
        "\n",
        "    def run(self, messages, text_only: bool = True):\n",
        "        if not isinstance(messages, list):\n",
        "            raise ValueError(\"messages must be a list\")\n",
        "\n",
        "        openai.api_key = self.openai_api_key\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=self.model_name, messages=messages\n",
        "        )\n",
        "\n",
        "        if text_only:\n",
        "            return response.choices[0].message.content\n",
        "\n",
        "        return response\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCU7FfhIR6yw"
      },
      "source": [
        "#### ❓ Question #3:\n",
        "\n",
        "When calling the OpenAI API - are there any ways we can achieve more reproducible outputs?\n",
        "\n",
        "> NOTE: Check out [this section](https://platform.openai.com/docs/guides/text-generation/) of the OpenAI documentation for the answer!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"background-color: #2b2c4f; padding: 10px; border-radius: 5px; border: 1px solid #b3d9ff; color: #fff;\">\n",
        "### &#x2611; Answer\n",
        "\n",
        "1. We can use the `temperature` parameter to control the randomness of the output.\n",
        "2. We can use the `top_p` parameter to control the diversity of the output.\n",
        "3. We can use the `stop` parameter to control the stopping of the output.\n",
        "\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5wcjMLCR6yw"
      },
      "source": [
        "### Creating and Prompting OpenAI's `gpt-4o-mini`!\n",
        "\n",
        "Let's tie all these together and use it to prompt `gpt-4o-mini`!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "WIfpIot7R6yw"
      },
      "outputs": [],
      "source": [
        "from aimakerspace.openai_utils.prompts import (\n",
        "    UserRolePrompt,\n",
        "    SystemRolePrompt,\n",
        "    AssistantRolePrompt,\n",
        ")\n",
        "\n",
        "from aimakerspace.openai_utils.chatmodel import ChatOpenAI\n",
        "\n",
        "chat_openai = ChatOpenAI()\n",
        "user_prompt_template = \"{content}\"\n",
        "user_role_prompt = UserRolePrompt(user_prompt_template)\n",
        "system_prompt_template = (\n",
        "    \"You are an expert in {expertise}, you always answer in a kind way.\"\n",
        ")\n",
        "system_role_prompt = SystemRolePrompt(system_prompt_template)\n",
        "\n",
        "messages = [\n",
        "    system_role_prompt.create_message(expertise=\"Python\"),\n",
        "    user_role_prompt.create_message(\n",
        "        content=\"What is the best way to write a loop?\"\n",
        "    ),\n",
        "]\n",
        "\n",
        "response = chat_openai.run(messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHo7lssNR6yw",
        "outputId": "1d3823fa-bb6b-45f6-ddba-b41686388324"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The best way to write a loop in Python depends on the specific task you're trying to accomplish. Here are a few common ways to write loops, along with tips to ensure they are efficient and easy to read:\n",
            "\n",
            "### For Loop\n",
            "The `for` loop is commonly used for iterating over a sequence (like a list, tuple, or string).\n",
            "\n",
            "```python\n",
            "# Example: Iterating over a list of numbers\n",
            "numbers = [1, 2, 3, 4, 5]\n",
            "for number in numbers:\n",
            "    print(number)\n",
            "```\n",
            "\n",
            "**Tips:**\n",
            "- Use meaningful variable names to enhance readability.\n",
            "- If you need both index and value, you can use `enumerate()`.\n",
            "\n",
            "```python\n",
            "for index, value in enumerate(numbers):\n",
            "    print(f\"Index: {index}, Value: {value}\")\n",
            "```\n",
            "\n",
            "### While Loop\n",
            "The `while` loop continues to execute as long as a specified condition is true.\n",
            "\n",
            "```python\n",
            "# Example: Using a while loop to print numbers\n",
            "count = 0\n",
            "while count < 5:\n",
            "    print(count)\n",
            "    count += 1\n",
            "```\n",
            "\n",
            "**Tips:**\n",
            "- Ensure you modify a variable involved in the condition to avoid infinite loops.\n",
            "- Be cautious with long-running loops; consider adding a break condition.\n",
            "\n",
            "### List Comprehensions\n",
            "For simple tasks, you can use list comprehensions to loop and create lists more efficiently.\n",
            "\n",
            "```python\n",
            "# Example: Creating a list of squares\n",
            "squares = [x**2 for x in range(10)]\n",
            "```\n",
            "\n",
            "### Additional Suggestions\n",
            "- **Avoid using `range()` with a very large number in a `for` loop**, as it can consume a lot of memory. Instead, use `itertools.count()` for infinite sequences or generators.\n",
            "- **Keep the loop body simple.** If the logic starts to get complicated, consider breaking it out into a function.\n",
            "- **Use meaningful comments** when necessary to explain complex logic.\n",
            "\n",
            "Remember, the \"best\" way can be subjective to your specific need, but prioritizing clarity and efficiency will always serve you well! If you have a specific use case in mind, feel free to share, and I’d be happy to help further!\n"
          ]
        }
      ],
      "source": [
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2nxxhB2R6yy"
      },
      "source": [
        "## Task 5: Retrieval Augmented Generation\n",
        "\n",
        "Now we can create a RAG prompt - which will help our system behave in a way that makes sense!\n",
        "\n",
        "There is much you could do here, many tweaks and improvements to be made!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "D1hamzGaR6yy"
      },
      "outputs": [],
      "source": [
        "RAG_PROMPT_TEMPLATE = \"\"\" \\\n",
        "Use the provided context to answer the user's query.\n",
        "\n",
        "You may not answer the user's query unless there is specific context in the following text.\n",
        "\n",
        "If you do not know the answer, or cannot answer, please respond with \"I don't know\".\n",
        "\"\"\"\n",
        "\n",
        "rag_prompt = SystemRolePrompt(RAG_PROMPT_TEMPLATE)\n",
        "\n",
        "USER_PROMPT_TEMPLATE = \"\"\" \\\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "User Query:\n",
        "{user_query}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "user_prompt = UserRolePrompt(USER_PROMPT_TEMPLATE)\n",
        "\n",
        "class RetrievalAugmentedQAPipeline:\n",
        "    def __init__(self, llm: ChatOpenAI(), vector_db_retriever: VectorDatabase) -> None:\n",
        "        self.llm = llm\n",
        "        self.vector_db_retriever = vector_db_retriever\n",
        "\n",
        "    def run_pipeline(self, user_query: str) -> str:\n",
        "        context_list = self.vector_db_retriever.search_by_text(user_query, k=4)\n",
        "\n",
        "        context_prompt = \"\"\n",
        "        for context in context_list:\n",
        "            context_prompt += context[0] + \"\\n\"\n",
        "\n",
        "        formatted_system_prompt = rag_prompt.create_message()\n",
        "\n",
        "        formatted_user_prompt = user_prompt.create_message(user_query=user_query, context=context_prompt)\n",
        "\n",
        "        return {\"response\" : self.llm.run([formatted_system_prompt, formatted_user_prompt]), \"context\" : context_list}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZIJI19uR6yz"
      },
      "source": [
        "#### ❓ Question #4:\n",
        "\n",
        "What prompting strategies could you use to make the LLM have a more thoughtful, detailed response?\n",
        "\n",
        "What is that strategy called?\n",
        "\n",
        "> NOTE: You can look through the Week 1 Day 1 \"Prompting OpenAI Like A Developer\" material for an answer to this question!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"background-color: #2b2c4f; padding: 10px; border-radius: 5px; border: 1px solid #b3d9ff; color: #fff;\">\n",
        "### &#x2611; Answer\n",
        "\n",
        "1. We can use specific prompting strategies to make the LLM have a more thoughtful, detailed response. Ex: RAG, Prompting, etc.\n",
        "2. We can make use of chain of thought prompting to make the LLM have a more thoughtful, detailed response. However, this might not always work in our favor based on certain requirements.\n",
        "3. Finally we can use \"Retrieval Augmented Generation\" (RAG).\n",
        "\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "kqbE9fZ6R6yz"
      },
      "outputs": [],
      "source": [
        "retrieval_augmented_qa_pipeline = RetrievalAugmentedQAPipeline(\n",
        "    vector_db_retriever=vector_db,\n",
        "    llm=chat_openai\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAGhaCGOR6yz",
        "outputId": "e4fb3a1b-d2bc-4e18-ec31-dc0adf767163"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'response': \"The 'Michael Eisner Memorial Weak Executive Problem' refers to a situation where a CEO or startup founder, who has a background in a specific area (like product management, sales, or marketing), hires a weak executive in that same area. This often happens because the leader struggles to let go of their former role and intentionally or unintentionally selects someone less capable, allowing them to remain the primary authority in that function. The term is named after Michael Eisner, the former CEO of Disney, who, despite being a successful TV network executive, faced challenges with the performance of ABC after its acquisition, indicating that strong leaders may still encounter difficulties when they overestimate their ability to manage areas outside their expertise.\",\n",
              " 'context': [('ordingly.\\nSeventh, when hiring the executive to run your former specialty, be\\ncareful you don’t hire someone weak on purpose.\\nThis sounds silly, but you wouldn’t believe how oaen it happens.\\nThe CEO who used to be a product manager who has a weak\\nproduct management executive. The CEO who used to be in\\nsales who has a weak sales executive. The CEO who used to be\\nin marketing who has a weak marketing executive.\\nI call this the “Michael Eisner Memorial Weak Executive Problem” — aaer the CEO of Disney who had previously been a brilliant TV network executive. When he bought ABC at Disney, it\\npromptly fell to fourth place. His response? “If I had an extra\\ntwo days a week, I could turn around ABC myself.” Well, guess\\nwhat, he didn’t have an extra two days a week.\\nA CEO — or a startup founder — oaen has a hard time letting\\ngo of the function that brought him to the party. The result: you\\nhire someone weak into the executive role for that function so\\nthat you can continue to be “the man” — cons',\n",
              "   0.6582125113300632),\n",
              "  ('m. They have areas where they are truly deXcient in judgment or skill set. That’s just life. Almost nobody is brilliant\\nat everything. When hiring and when Hring executives, you\\nmust therefore focus on strength rather than lack of weakness. Everybody has severe weaknesses even if you can’t see\\nthem yet. When managing, it’s oaen useful to micromanage and\\nto provide remedial training around these weaknesses. Doing so\\nmay make the diWerence between an executive succeeding or\\nfailing.\\nFor example, you might have a brilliant engineering executive\\nwho generates excellent team loyalty, has terriXc product judgment and makes the trains run on time. This same executive\\nmay be very poor at relating to the other functions in the company. She may generate far more than her share of cross-functional conYicts, cut herself oW from critical information, and\\nsigniXcantly impede your ability to sell and market eWectively.\\nYour alternatives are:\\n(a) Macro-manage and give her an annual or quarterly object',\n",
              "   0.5088372362539735),\n",
              "  ('ed?\\nIn reality — as opposed to Marc’s warped view of reality — it will\\nbe extremely helpful for Marc [if he were actually the CEO,\\nwhich he is not] to meet with the new head of engineering daily\\nwhen she comes on board and review all of her thinking and\\ndecisions. This level of micromanagement will accelerate her\\ntraining and improve her long-term eWectiveness. It will make\\nher seem smarter to the rest of the organization which will build\\ncredibility and conXdence while she comes up to speed. Micromanaging new executives is generally a good idea for a limited\\nperiod of time.\\nHowever, that is not the only time that it makes sense to micro66 The Pmarca Blog Archives\\nmanage executives. It turns out that just about every executive\\nin the world has a few things that are seriously wrong with\\nthem. They have areas where they are truly deXcient in judgment or skill set. That’s just life. Almost nobody is brilliant\\nat everything. When hiring and when Hring executives, you\\nmust therefore focus o',\n",
              "   0.47903669405979227),\n",
              "  ('nYicts, cut herself oW from critical information, and\\nsigniXcantly impede your ability to sell and market eWectively.\\nYour alternatives are:\\n(a) Macro-manage and give her an annual or quarterly objective\\nto Xx it, or…\\n(b) Intensively micromanage her interactions until she learns\\nthe fundamental interpersonal skills required to be an eWective\\nexecutive.\\nI am arguing that doing (a) will likely result in weak performance. The reason is that she very likely has no idea how to be\\neWective with her peers. If somebody is an executive, it’s very\\nlikely that somewhere along the line somebody gave her feedback — perhaps abstractly — about all of her weaknesses. Yet\\nthe weakness remains. As a result, executives generally require\\nmore hands-on management than lower level employees to\\nimprove weak areas.\\nSo, micromanagement is like Xne wine. A little at the right times\\nwill really enhance things; too much all the time and you’ll end\\nup in rehab.\\nPart 8: Hiring, managing, promoting, and Dring execut',\n",
              "   0.4681083391380689)]}"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retrieval_augmented_qa_pipeline.run_pipeline(\"What is the 'Michael Eisner Memorial Weak Executive Problem'?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 🏗️ Activity #1:\n",
        "\n",
        "Enhance your RAG application in some way!\n",
        "\n",
        "Suggestions are:\n",
        "\n",
        "- Allow it to work with PDF files\n",
        "- Implement a new distance metric\n",
        "- Add metadata support to the vector database\n",
        "\n",
        "While these are suggestions, you should feel free to make whatever augmentations you desire!\n",
        "\n",
        "> NOTE: These additions might require you to work within the `aimakerspace` library - that's expected!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### For my assignment, I will be using the Whisper model to transcribe audio/video files.\n",
        "### Convert the transcript to a text file in .pdf format and then use the RAG pipeline to answer questions about the transcript.\n",
        "\n",
        "#### To make it a little more fun, let us get Dr.Greg Loughnane recent video from youtube [https://www.youtube.com/watch?v=g24eW5q5Ehw&t=2s] and transcribe it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: numpy 1.23.5\n",
            "Uninstalling numpy-1.23.5:\n",
            "  Successfully uninstalled numpy-1.23.5\n",
            "Found existing installation: numba 0.60.0\n",
            "Uninstalling numba-0.60.0:\n",
            "  Successfully uninstalled numba-0.60.0\n",
            "\u001b[33mWARNING: Skipping whisper as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: openai-whisper 20240930\n",
            "Uninstalling openai-whisper-20240930:\n",
            "  Successfully uninstalled openai-whisper-20240930\n",
            "Found existing installation: torch 2.5.1\n",
            "Uninstalling torch-2.5.1:\n",
            "  Successfully uninstalled torch-2.5.1\n",
            "Found existing installation: torchvision 0.20.1+cpu\n",
            "Uninstalling torchvision-0.20.1+cpu:\n",
            "  Successfully uninstalled torchvision-0.20.1+cpu\n",
            "Found existing installation: torchaudio 2.5.1+cpu\n",
            "Uninstalling torchaudio-2.5.1+cpu:\n",
            "  Successfully uninstalled torchaudio-2.5.1+cpu\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting numpy==1.23.5\n",
            "  Using cached numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Using cached numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "Installing collected packages: numpy\n",
            "Successfully installed numpy-1.23.5\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting numba==0.56.4\n",
            "  Using cached numba-0.56.4.tar.gz (2.4 MB)\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25lerror\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m \u001b[31m[21 lines of output]\u001b[0m\n",
            "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
            "  \u001b[31m   \u001b[0m   File \"/mnt/c/Users/email/Desktop/bootcamp/AIE5/02_Embeddings_and_RAG/.venv/lib/python3.11/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 353, in <module>\n",
            "  \u001b[31m   \u001b[0m     main()\n",
            "  \u001b[31m   \u001b[0m   File \"/mnt/c/Users/email/Desktop/bootcamp/AIE5/02_Embeddings_and_RAG/.venv/lib/python3.11/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 335, in main\n",
            "  \u001b[31m   \u001b[0m     json_out['return_val'] = hook(**hook_input['kwargs'])\n",
            "  \u001b[31m   \u001b[0m                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  \u001b[31m   \u001b[0m   File \"/mnt/c/Users/email/Desktop/bootcamp/AIE5/02_Embeddings_and_RAG/.venv/lib/python3.11/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 118, in get_requires_for_build_wheel\n",
            "  \u001b[31m   \u001b[0m     return hook(config_settings)\n",
            "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
            "  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-x3ise44y/overlay/lib/python3.11/site-packages/setuptools/build_meta.py\", line 334, in get_requires_for_build_wheel\n",
            "  \u001b[31m   \u001b[0m     return self._get_build_requires(config_settings, requirements=[])\n",
            "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-x3ise44y/overlay/lib/python3.11/site-packages/setuptools/build_meta.py\", line 304, in _get_build_requires\n",
            "  \u001b[31m   \u001b[0m     self.run_setup()\n",
            "  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-x3ise44y/overlay/lib/python3.11/site-packages/setuptools/build_meta.py\", line 522, in run_setup\n",
            "  \u001b[31m   \u001b[0m     super().run_setup(setup_script=setup_script)\n",
            "  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-x3ise44y/overlay/lib/python3.11/site-packages/setuptools/build_meta.py\", line 320, in run_setup\n",
            "  \u001b[31m   \u001b[0m     exec(code, locals())\n",
            "  \u001b[31m   \u001b[0m   File \"<string>\", line 51, in <module>\n",
            "  \u001b[31m   \u001b[0m   File \"<string>\", line 48, in _guard_py_ver\n",
            "  \u001b[31m   \u001b[0m RuntimeError: Cannot install on Python version 3.11.4; only versions >=3.7,<3.11 are supported.\n",
            "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-wt3xvvxy\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-wt3xvvxy\n",
            "  Resolved https://github.com/openai/whisper.git to commit 517a43ecd132a2089d85f4ebc044728a71d49f6e\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: more-itertools in ./.venv/lib/python3.11/site-packages (from openai-whisper==20240930) (10.6.0)\n",
            "Collecting numba (from openai-whisper==20240930)\n",
            "  Using cached numba-0.60.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: numpy in ./.venv/lib/python3.11/site-packages (from openai-whisper==20240930) (1.23.5)\n",
            "Requirement already satisfied: tiktoken in ./.venv/lib/python3.11/site-packages (from openai-whisper==20240930) (0.8.0)\n",
            "Collecting torch (from openai-whisper==20240930)\n",
            "  Using cached torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Requirement already satisfied: tqdm in ./.venv/lib/python3.11/site-packages (from openai-whisper==20240930) (4.67.1)\n",
            "Requirement already satisfied: triton>=2 in ./.venv/lib/python3.11/site-packages (from openai-whisper==20240930) (3.1.0)\n",
            "Requirement already satisfied: filelock in ./.venv/lib/python3.11/site-packages (from triton>=2->openai-whisper==20240930) (3.16.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in ./.venv/lib/python3.11/site-packages (from numba->openai-whisper==20240930) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in ./.venv/lib/python3.11/site-packages (from tiktoken->openai-whisper==20240930) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in ./.venv/lib/python3.11/site-packages (from tiktoken->openai-whisper==20240930) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in ./.venv/lib/python3.11/site-packages (from torch->openai-whisper==20240930) (4.12.2)\n",
            "Requirement already satisfied: networkx in ./.venv/lib/python3.11/site-packages (from torch->openai-whisper==20240930) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in ./.venv/lib/python3.11/site-packages (from torch->openai-whisper==20240930) (3.1.5)\n",
            "Requirement already satisfied: fsspec in ./.venv/lib/python3.11/site-packages (from torch->openai-whisper==20240930) (2024.12.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./.venv/lib/python3.11/site-packages (from torch->openai-whisper==20240930) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./.venv/lib/python3.11/site-packages (from torch->openai-whisper==20240930) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./.venv/lib/python3.11/site-packages (from torch->openai-whisper==20240930) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./.venv/lib/python3.11/site-packages (from torch->openai-whisper==20240930) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./.venv/lib/python3.11/site-packages (from torch->openai-whisper==20240930) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./.venv/lib/python3.11/site-packages (from torch->openai-whisper==20240930) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./.venv/lib/python3.11/site-packages (from torch->openai-whisper==20240930) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./.venv/lib/python3.11/site-packages (from torch->openai-whisper==20240930) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./.venv/lib/python3.11/site-packages (from torch->openai-whisper==20240930) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./.venv/lib/python3.11/site-packages (from torch->openai-whisper==20240930) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./.venv/lib/python3.11/site-packages (from torch->openai-whisper==20240930) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./.venv/lib/python3.11/site-packages (from torch->openai-whisper==20240930) (12.4.127)\n",
            "Requirement already satisfied: sympy==1.13.1 in ./.venv/lib/python3.11/site-packages (from torch->openai-whisper==20240930) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.11/site-packages (from sympy==1.13.1->torch->openai-whisper==20240930) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.11/site-packages (from jinja2->torch->openai-whisper==20240930) (3.0.2)\n",
            "Using cached numba-0.60.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
            "Using cached torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl (906.5 MB)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803669 sha256=2abe66cb616ce8e14fc310c184bf753536b7df93986a7a5f400bb21db07c9cab\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-irelfn3_/wheels/1f/1d/98/9583695e6695a6ac0ad42d87511097dce5ba486647dbfecb0e\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: numba, torch, openai-whisper\n",
            "Successfully installed numba-0.60.0 openai-whisper-20240930 torch-2.5.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
            "Requirement already satisfied: torch in ./.venv/lib/python3.11/site-packages (2.5.1)\n",
            "Collecting torchvision\n",
            "  Using cached https://download.pytorch.org/whl/cpu/torchvision-0.20.1%2Bcpu-cp311-cp311-linux_x86_64.whl (1.8 MB)\n",
            "Collecting torchaudio\n",
            "  Using cached https://download.pytorch.org/whl/cpu/torchaudio-2.5.1%2Bcpu-cp311-cp311-linux_x86_64.whl (1.7 MB)\n",
            "Requirement already satisfied: filelock in ./.venv/lib/python3.11/site-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in ./.venv/lib/python3.11/site-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in ./.venv/lib/python3.11/site-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in ./.venv/lib/python3.11/site-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in ./.venv/lib/python3.11/site-packages (from torch) (2024.12.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./.venv/lib/python3.11/site-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./.venv/lib/python3.11/site-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./.venv/lib/python3.11/site-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./.venv/lib/python3.11/site-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./.venv/lib/python3.11/site-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./.venv/lib/python3.11/site-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./.venv/lib/python3.11/site-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./.venv/lib/python3.11/site-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./.venv/lib/python3.11/site-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./.venv/lib/python3.11/site-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./.venv/lib/python3.11/site-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./.venv/lib/python3.11/site-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in ./.venv/lib/python3.11/site-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in ./.venv/lib/python3.11/site-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in ./.venv/lib/python3.11/site-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./.venv/lib/python3.11/site-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n",
            "Installing collected packages: torchvision, torchaudio\n",
            "Successfully installed torchaudio-2.5.1+cpu torchvision-0.20.1+cpu\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# # Reinstalling numpy and numba as they are not compatible with the latest whisper model\n",
        "\n",
        "# First uninstall current packages\n",
        "%pip uninstall -y numpy numba whisper openai-whisper torch torchvision torchaudio\n",
        "\n",
        "# Install specific versions that are compatible\n",
        "%pip install numpy==1.23.5\n",
        "%pip install numba==0.56.4\n",
        "\n",
        "# Now installing whisper and torch\n",
        "%pip install git+https://github.com/openai/whisper.git \n",
        "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/mnt/c/Users/email/Desktop/bootcamp/AIE5/02_Embeddings_and_RAG/.venv/lib/python3.11/site-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        }
      ],
      "source": [
        "# Lets get openai's latest whisper model\n",
        "# Lets load the model (base) for now\n",
        "# THIS IS GOING TO TAKE A WHILE TO LOAD\n",
        "\n",
        "import whisper\n",
        "\n",
        "# Load the Whisper model\n",
        "model = whisper.load_model(\"base\")  # You can choose from \"tiny\", \"base\", \"small\", \"medium\", \"large\"\n",
        "\n",
        "# Path to your audio file\n",
        "audio_file = \"data/greg-audio.wav\"\n",
        "\n",
        "# Transcribe the audio file\n",
        "result = model.transcribe(audio_file)\n",
        "\n",
        "transcript = result[\"text\"]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " All right, hey everyone, welcome back to Coding Temple's Agile Leaders. We help product and tech leaders execute and innovate in these rapidly changing times with more confidence and velocity. I'm your host, Evan Shye. Today we are joined by my friend, Greg Lachnane, the co-founder and CEO of AI Maker Space, where him and his incredible team are building the world's leading community for building production LLM applications. So this episode is for the technologists out there looking to push the bleeding edge of AI in their organization. Thank you so much for being here, Greg. Yeah, thanks for having me, Evan. It's awesome to be here with you. Well, I have the pleasure of knowing a little bit about your background and how impressive it is and why you are my go-to source for everything related to AI, but maybe you can share a little bit about your journey with the audience here. Yeah, you know, in 2015, I graduated with my PhD. It was an optimization at the time. And part of the reason I even got it was because I kind of loved teaching. And I started doing that as an undergrad. So quickly kind of came out of school, got into government contracting, consulting and started work with teams to commercialize tech. And that kind of led me into liking the startup vibe more than the big companies. And I found it was very hard to make money with research. And even though I started to do some consulting outside of government contracting with actual startups, I found it was really still hard to make money with AI at the time, 16, 17, 18. And I started doing a lot of sort of just research for the CTO and you're kind of taking this work that you do and you're thrown it over the wall of the engineering team and it often dies on the mind. You know, this kind of pushed me more and more towards trying to get inside and build something with a team towards product management. So I kind of went and I went to entrepreneurship school, dabbled in some startups that weren't mind all along I'm teaching and then COVID hits. And I realized like, man, online teaching and learning is like, this is like the future. I like, I have got to get into this. I've always loved teaching. It's never really paid, but I got the feeling at the time this is what I should be focused on. 2020 actually take a full time job teaching. So I'm teaching five days a week. I'm trying to become like the best at online teaching and learning. And you know, it was a big opportunity because still most people have never been to a Zoom room. That's like really, really well run. It's not like a thing that people have experienced. But it can be done. And you know, this is something I've been working on for the last four or five years. I tried to launch a course back then teaching people 3D printing. It was a disaster. I don't really know what I was doing. Headed out to Silicon Valley to sort of learn startups, learn the industry of ed tech, understand boot camps. It's kind of got me into a role at the company called fourth brain, which is very close to deep learning AI and got me kind of close to a lot of people that are kind of at the top of the industry. I looked around and I realized like this is what I want to be doing building these boot camps, but this sort of VC product, VC backed ed tech boot camp business model. It's not quite right. And so, you know, after Chad GBT came out 2023, I realized, man, this is the year. I want to do this a little bit better than I've ever seen anybody do it. This kind of led to what AI maker space has become today. So we're building boot camps out on the edge of what's possible with open source. And that's LLM today in production. I love it, man. I knew there were some similarities in our journey, but I didn't quite appreciate how much. I guess I've been an entrepreneur my entire career, but did some time in an academia, a few of us in a PhD program and was publishing research and realizing how far of a distance or golf there was between the work we were publishing and the impact I was having on people's lives and ended up starting trying to do skill development, building applications to deliver to that skill development to make a bigger impact in people's lives. And then, you know, a lot of philosophical alignment in terms of how can we do that better and ultimately brought both of us here, I think. Were there any skills that were kind of most transferable from that past life into more of the operator seat, product leader seat? Yeah, I mean, you know, I think when I look across all of it, it's kind of like this willingness to sort of like attack one thing as hard as you can at each period. So it kind of is like resilience is number one. It's kind of like cookie cutter thing, but like, you know, like I was deeply under employed for long stretches, you know, throughout this journey. And it's just part of like continuing to just smash the grind. But each sort of skill I learned a long way, like doing research, very important if you're going to do consult thing, right? And then building a startup, actually the way you build it out to be in with and find product market fit and figure out what you should be building is kind of through consulting. And so like, you know, each of these things kind of stacks on each other. And then it was very, very helpful to go sort of get the broad perspective of entrepreneurship school, dabble a little bit of this and that. And then as a CEO, I'm finding I go back to some of that, you know, okay, I have a CFO day. I got to go pick up how to actually do the balance sheet stuff. Okay, I have this kind of day. And, you know, I think that that's been, it's just kind of all come together because the startup CEO is kind of an everything job. So you kind of have to stack it one piece at a time. Amen, man. Even something as seemingly singularly constrained to science or research, but just the scientific method or running experiments appropriately and developing hypotheses. And it always doesn't have to be this like perfectly elaborate experiment, but even just thinking in ways where you can actually test hypotheses or expose where you're wrong. I think is a useful thing for a lot of entrepreneurs who are trying to. That's right. And I think like I've talked to, you know, mentors of mine, whatever, it's like this idea that what is your hypothesis? Because the thing about business is like you have to figure out what's true about your customers, you have to figure out what's true about what's going wrong in your company. And it's like, it's like the opposite of sort of like beginning emotional about it and whatever you feel about it. And so you've got to be able to say, okay, and the decision making framework of the hypothesis is very useful because otherwise like if you're trying to think about everything and how it engages in interacts, like you can't make any decisions. It's like this hypothesis, this is how I'm going to test it. You know, it's very, very, it's exactly that in business. Yeah, that you have to have a scientific method, you know, let's get to the truth as fast as possible because we're going to get there one way or another and like let's not pay a toll for the fee tour, you know. So kind of leaning back on, I guess some of your consulting work and then now what you're seeing with technologists and technical leaders inside enterprises, you know, obviously a lot of organizations, most probably organizations are starting to really look at AI and recognize that there are meaningful implications that this is going to have on our business. But what do we ultimately do about it? What is the strategy? How do we actualize that strategy and create value for the organization? Is there a common thread or a primary set of challenges that you see technology leaders face when implementing AI strategies in their organization? Yeah, I mean...\n"
          ]
        }
      ],
      "source": [
        "print(transcript)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PDF created successfully at data/audio-transcript.pdf\n"
          ]
        }
      ],
      "source": [
        "# Lets save the transcript to a text file in .pdf format with font size 12 and font family Arialfrom reportlab.pdfgen import canvas\n",
        "from reportlab.lib.pagesizes import letter\n",
        "from reportlab.pdfbase import pdfmetrics\n",
        "from reportlab.pdfbase.ttfonts import TTFont\n",
        "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
        "from reportlab.platypus import SimpleDocTemplate, Paragraph\n",
        "from reportlab.lib.units import inch\n",
        "\n",
        "def create_pdf_transcript(transcript_text, output_file=\"data/audio-transcript.pdf\"):\n",
        "    # Create the PDF document\n",
        "    doc = SimpleDocTemplate(\n",
        "        output_file,\n",
        "        pagesize=letter,\n",
        "        rightMargin=72,\n",
        "        leftMargin=72,\n",
        "        topMargin=72,\n",
        "        bottomMargin=72\n",
        "    )\n",
        "    \n",
        "    # Create a list to store the flowables (content)\n",
        "    story = []\n",
        "    \n",
        "    # Create a style for the text\n",
        "    styles = getSampleStyleSheet()\n",
        "    normal_style = ParagraphStyle(\n",
        "        'CustomNormal',\n",
        "        parent=styles['Normal'],\n",
        "        fontSize=12,\n",
        "        leading=14,  # Line spacing\n",
        "        fontName='Helvetica'\n",
        "    )\n",
        "    \n",
        "    # Split the transcript into paragraphs and add them to the story\n",
        "    paragraphs = transcript_text.split(' ')\n",
        "    for para in paragraphs:\n",
        "        p = Paragraph(para.replace('\\n', '<br/>'), normal_style)\n",
        "        story.append(p)\n",
        "    \n",
        "    # Build the PDF\n",
        "    doc.build(story)\n",
        "    \n",
        "    print(f\"PDF created successfully at {output_file}\")\n",
        "\n",
        "# Create the PDF using your transcript\n",
        "create_pdf_transcript(transcript)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyPDF2 in ./.venv/lib/python3.11/site-packages (3.0.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# Install PyPDF2\n",
        "%pip install PyPDF2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\"All right, hey everyone, welcome back to Coding Temple's Agile Leaders\\nWe help product and tech leaders execute and innovate in these rapidly changing\\ntimes with more confidence and velocity\\nI'm your host, Evan Shye\\nToday we are joined by my friend, Greg Lachnane, the co-founder and CEO of AI\\nMaker Space, where him and his incredible team are building the world's leading\\ncommunity for building production LLM applications\\nSo this episode is for the technologists out there looking to push the bleeding edge of\\nAI in their organization\\nThank you so much for being here, Greg\\nYeah, thanks for having me, Evan\\nIt's awesome to be here with you\\nWell, I have the pleasure of knowing a little bit about your background and how\\nimpressive it is and why you are my go-to source for everything related to AI, but\\nmaybe you can share a little bit about your journey with the audience here\\nYeah, you know, in 2015, I graduated with my PhD\\nIt was an optimization at the time\\nAnd part of the reason I even got it was because I kind of loved teaching\\nAnd I started doing that as an undergrad\\nSo quickly kind of came out of school, got into government contracting, consulting and\\nstarted work with teams to commercialize tech\\nAnd that kind of led me into liking the startup vibe more than the big companies\\nAnd I found it was very hard to make money with research\\nAnd even though I started to do some consulting outside of government contracting\\nwith actual startups, I found it was really still hard to make money with AI at the time,\\n16, 17, 18\\nAnd I started doing a lot of sort of just research for the CTO and you're kind of taking\\nthis work that you do and you're thrown it over the wall of the engineering team and it\\noften dies on the mind\\nYou know, this kind of pushed me more and more towards trying to get inside and\\nbuild something with a team towards product management\\nSo I kind of went and I went to entrepreneurship school, dabbled in some startups that\\nweren't mind all along I'm teaching and then COVID hits\\nAnd I realized like, man, online teaching and learning is like, this is like the future\\nI like, I have got to get into this\\nI've always loved teaching\\nIt's never really paid, but I got the feeling at the time this is what I should be focused\\non\\n2020 actually take a full time job teaching\\nSo I'm teaching five days a week\\nI'm trying to become like the best at online teaching and learning\\nAnd you know, it was a big opportunity because still most people have never been to\\na Zoom room\\nThat's like really, really well run\\nIt's not like a thing that people have experienced\\n\", \"But it can be done\\nAnd you know, this is something I've been working on for the last four or five years\\nI tried to launch a course back then teaching people 3D printing\\nIt was a disaster\\nI don't really know what I was doing\\nHeaded out to Silicon Valley to sort of learn startups, learn the industry of EdTech,\\nunderstand boot camps\\nIt's kind of got me into a role at the company called fourth brain, which is very close to\\ndeep learning AI and got me kind of close to a lot of people that are kind of at the top\\nof the industry\\nI looked around and I realized like this is what I want to be doing building these boot\\ncamps, but this sort of VC product, VC backed, EdTech boot camp business model\\nIt's not quite right\\nAnd so, you know, after Chad GBT came out, 2023, I realized, man, this is the year\\nI want to do this a little bit better than I've ever seen anybody do it\\nThis kind of led to what AI maker space has become today\\nSo we're building boot camps out on the edge of what's possible with open source\\nAnd that's LLM today in production\\nI love it, man\\nI knew there were some similarities in our journey, but I didn't quite appreciate how\\nmuch\\nI guess I've been an entrepreneur my entire career, but did some time in an\\nacademia, a few of us in a PhD program and was publishing research and realizing\\nhow far of a distance or golf there was between the work we were publishing and the\\nimpact I was having on people's lives and ended up starting trying to do skill\\ndevelopment, building applications to deliver to that skill development, to make a\\nbigger impact in people's lives\\nAnd then, you know, a lot of philosophical alignment in terms of how can we do that\\nbetter and ultimately brought both of us here, I think\\nWere there any skills that were kind of most transferable from that past life into more\\nof the operator seat, product leader seat? Yeah, I mean, you know, I think when I look\\nacross all of it, it's kind of like this willingness to sort of like attack one thing as hard as\\nyou can at each period\\nSo it kind of is like resilience is number one\\nIt's kind of like cookie cutter thing, but like, you know, like I was deeply under\\nemployed for long stretches, you know, throughout this journey\\nAnd it's just part of like continuing to just smash the grind\\nBut each sort of skill I learned a long way, like doing research, very important if you're\\ngoing to do consult things, right? And then building a startup, actually the way you\\nbuild it out to begin with and find product market fit and figure out what you should be\\nbuilding is kind of through consulting\\nAnd so like, you know, each of these things kind of stacks on each other\\nAnd then it was very, very helpful to go sort of get the broad perspective of\\nentrepreneurship school, dabble a little bit of this and that\\n\", \"And then as a CEO, I'm finding I go back to some of that, you know, okay, I have a\\nCFO day\\nI got to go pick up how to actually do the balance sheet stuff\\nOkay, I have this kind of day\\nAnd, you know, I think that that's been, it's just kind of all come together because the\\nstartup CEO is kind of an everything job\\nSo you kind of have to stack it one piece at a time\\nAmen, man\\nEven something as seemingly singularly constrained to science or research, but just\\nthe scientific method or running experiments appropriately and developing\\nhypotheses\\nAnd it always doesn't have to be this like perfectly elaborate experiment, but even just\\nthinking in ways where you can actually test hypotheses or expose where you're\\nwrong\\nI think is a useful thing for a lot of entrepreneurs who are trying to\\nThat's right\\nAnd I think like I've talked to, you know, mentors of mine, whatever, it's like this idea\\nthat what is your hypothesis? Because the thing about business is like, you have to\\nfigure out what's true about your customers, you have to figure out what's true about\\nwhat's going wrong in your company\\nAnd it's like, it's like the opposite of sort of like getting emotional about it and whatever\\nyou feel about it\\nAnd so you've got to be able to say, okay, and the decision making framework of the\\nhypothesis is very useful because otherwise like if you're trying to think about\\neverything and how it engages in interacts, like you can't make any decisions\\nIt's like this hypothesis, this is how I'm going to test it\\nYou know, it's very, very, it's exactly that in business\\nYeah, that you have to have a scientific method, you know, let's get to the truth as fast\\nas possible because we're going to get there one way or another and like that's not\\npay a toll for the fee tour, you know\\nSo kind of leaning back on, I guess some of your consulting work and then now what\\nyou're seeing with technologists and technical leaders inside enterprises, you know,\\nobviously a lot of organizations, most probably organizations are starting to really look\\nat AI and recognize that there are meaningful implications that this is going to have on\\nour business\\nBut what do we ultimately do about it? What is the strategy? How do we actualize that\\nstrategy and create value for the organization? Is there a common thread or a primary\\nset of challenges that you see technology leaders face when implementing AI\\nstrategies in their organization? Yeah, I mean, I think that you have to sort of break\\ndown the industry into its component parts and you have to break down the\\ntechnology at the same time\\nSo, you know, in industry, you're going to prototype things and then you're going to\\nput them into production\\nOn the technology side, we really want to kind of differentiate between AI sort of\\nclassical machine learning, deep learning and then this sort of generative AI that we're\\n\", \"talking about when we talk about large language models\\nOf course, there are many, many fine lines there, but from a what you should be\\nbuilding for your customers perspective, you know, you want to understand, okay, top\\nlevel, yes, I need to go from prototype to production\\nYes, I need to understand AI versus generative AI\\nBut you know what your customers want and what is going to make their lives easier\\nAnd like part of the thing is, part of the dirty little secret is like, well, most products\\ntoday that are built do not actually require AI\\nAnd you know, of the ones that do require AI, most of them do not require generative\\nAI\\nSo you end up when you go and you take it, I'm only going to create business value\\nfrom my customers perspective\\nYou end up kind of taking this unsexy approach of saying, well, maybe I'll just do sort\\nof classic product management\\nMaybe I'll do more classical AI product management\\nBut you know, the board's asking about LLAMs\\nEverybody wants to know what we're doing with LLAMs\\nChat GBT came out\\nEverybody's freaking out\\nWhat are we doing about it? It's important to have something there\\nAnd it's important to start moving down this prototyping to production pathway\\nAnd so this is where I'll sort of leave the classical AI aside and talk about generative\\nbecause that's what people want to hear about today\\nI think one of the things is there are companies that are good at prototyping already\\nThey're great at it\\nAnd they're sitting there and they're like, we got these prototypes\\nWe're dangling the candy in front of people that are in the company\\nThey're like, man, what are we waiting for? Let's push these things to production and\\nscale them out\\nThese are amazing applications\\nAnd there's a real hang up there in production\\nSo these are the financial industries, this is the insurance industry\\nThis is these are the guys that have an all digital product\\nSo it's all digital\\nIt's all about the data\\nIt always has been, you know, quants are the OG, ML and AI people\\nMaking money off and making money has always kind of led the way here\\nSo these industries that build products based on that idea are still very much leading\\nthe way\\nAnd so, you know, when I talk to folks from industries like that, what you end up\\nhearing is going to appear\\nWell, a lot of these challenges of going to production, the infrastructure for LLMs in\\nproduction is different than the infrastructure for AI's in production\\nIt's classical AI in production\\nAnd by the nature of the large in large language models\\n\", \"And so you end up like having to figure out how to get new tools\\nAnd there are a lot of these open source edge tools that, you know, they're not well\\nsupported\\nSo in production, right, if something breaks at 1, 2, 3, 4 in the morning, who are you\\ngoing to call to make sure that you can fix it? And if the answer is, I don't have\\nanybody to call, well, we don't want to go to production\\nAnd this is a very important gap right now in the industry that we're going to continue\\nto try to create some value for folks in that space is one of, is one of our key strategic\\ngoals of this year\\nSo because we believe that's the open source edge\\nNow, most people are not there, all right? Most people are back in the productions in\\nthe prototyping phase\\nAnd in the prototyping phase, you have to sort of decide what should I be building?\\nWhy? How am I going to leverage tools like prompt engineering, like fine tuning, like\\nretrieval augmented generation, bragg? If you can't sort of intelligently even speak\\nabout these topics, let alone how they relate to one another and how they come\\ntogether holistically to create an app that has human level performance\\nThat's aligned with your customers\\nThat's giving a great experience\\nThat's not going to get you in trouble\\nAnd you're not very good at prototyping yet\\nAnd you should be spending your energies and your focus there\\nSo I think what you have to do is you have to look across your organization\\nYou have to be real honest about how mature are we from a technological standpoint\\nSome industries are just less mature, manufacturing, defense\\nThey tend to move slower and that's OK\\nSome other industries feel the heat of competition, the insurance, right? The financial,\\nthey're like, if we don't get on this, we're out of business\\nSo if you have to look at your industry, you have to look at your actual executive team\\nand the capabilities you have from a data science and machine learning perspective\\nnow\\nAnd you have to start building on that wherever you are\\nAnd whatever that looks like is going to be different for your particular situation\\nBut it always starts with proof concepts and prototypes\\nIt always moves into production\\nAnd you're always going to have to make that differentiation between classical\\nmachine learning deep learning and generative AI and no AI at all\\nSo it's tough to answer the question in general\\nBut that's my best right there\\nIt's a very, very useful framing and mental model that helps kind of bifurcate and\\norganize the different contexts that businesses or maybe the different phases that\\nbusinesses are ultimately in\\nAnd they're interesting points in both elements\\nI guess let's start with the\\n\", \"Well, actually, do you have a general sense or pulse, at least even anecdotally just\\nbased on your experience? Where do the majority of businesses fall right now? In the\\nproduction phase or the prototyping phase? Bass majority of businesses are stuck in\\nprototyping\\nVery, very few businesses that I've spoken to are actually out like\\nThey're like, yeah, yeah, we get it\\nWe understand how to use all the latest and greatest tools\\nWe're building that\\nOur people understand it\\nThe thing is we have these sort of like\\nOther infrastructure, security, whatever issues that are halting me now from creating\\nmassive value with these tools tomorrow\\nRight? And so that's the edge\\nMost people are somewhere getting started\\nOne, two, three POCs, prototypes\\nYou really have to sort of maybe get five or ten that actually really worked and you\\nknow you want to go to production with\\nSo it's kind of a long road from starting POCs to being ready to rock\\nTotally, totally get that\\nWe'll spend a meaningful amount of time in that kind of earlier phase and how you go\\nabout approaching it to hopefully create as much downstream value for customers as\\npossible\\nAlthough I will say that you really nicely elucidated some seemingly inevitable\\nchallenges that companies will face on the production side of it, particularly as it\\nrelates to skill gaps and capacity planning and all of that to ensure that they're not only\\nable to launch it in production but maintain it and continue to iterate on it\\nYeah, yeah\\nThe iteration has a whole other piece\\nYeah, yeah, yeah\\nI'm glad I bet\\nOkay, so we're in the earlier part of the journey as a company, you know, really\\nevaluating\\nOkay, we know, well, we have some early hypotheses about how we can create value\\nfor customers\\nI guess are there the frameworks with which you would advise product leaders or\\ntechnical leaders to utilize out of the gate to ensure that they are consistently orienting\\naround customer value and not kind of getting distracted by shiny objects? Yeah, I\\nmean, I mean, I would just, I would start with, you know, your last quarter, your last\\nyear's strategy and, you know, it's like, well, what are some of the initiatives that you\\nhave on there that could potentially be augmented with some of these newer\\ntechnologies? You know, like that, that, that sort of easiest, lowest hanging fruit\\nAnd then one of the other things is, I mean, that I recommend to people is like, go\\naround to, you know, your, your functional department head, your functions, your\\ndepartments, whatever\\nYou, you are, and you ask people to leave them\\n\", \"It's like, what are some things that your people like complain about having to do all the\\ntime that are pretty monotonous? Like, what are the things that, you know, and you're\\noften like, it's a customer support, right? It's a, it's the same question I'm answering\\nover and over\\nIt's the same freaking pipe I'm fixing 10,000 times\\nAnd the different maintenance person has to figure it out exactly the same way, even\\nthough it's already been done 15 times before\\nIt's like, where are you not transferring that sort of, that sort of learned experience and\\nknowledge to the next person, the next person, the next person? And how can you\\nsort of automate that? Or what questions is HR getting on, you know, policies\\nconstantly, right? You sort of question answering systems or great sort of framework\\nand mental model of use\\nLike, where are people asking questions that you get the same answer over and over,\\nright? And, and, you know, that, that to me is probably the place to start is, what's\\nbothering people about what they have to spend time on? That's sort of an internal\\napplication thing\\nSo questions are you answering for customers over and over and over? That's sort of\\nthe number one external application thing\\nAnd then, you know, look in your own strategy, maybe you can start there and see\\nwhat you can come up with\\nI love that\\nThe, the internal focus first feels like to your point, lowering fruit, safer, more reliable\\nI mean, by definition, you can talk directly to the customer, the customer is part of your\\norganization\\nSo probably a safer space to be\\nYou get, you capture some fast wins and you start to develop more confidence in the\\nmuscle and in the technology and you could probably build on that to some degree\\nYeah\\nYeah\\nAnd, and I think like one of the classic ones, even from classic A\\nI\\nwas like the auto quoting sales tool, right? It's like, why are we, why are we still\\nmanually quoting people? Like, but can you actually build something that your sales\\nteam wants to use is the real question, right? Not that you're like forcing them by\\nhooking cropped to sort of like, no, you have to pick this up otherwise\\nYeah\\nAnd so are you actually building things that people want? It's as much either testing\\nsite too\\nIt always matters, man\\nIs this something people actually want? And the best way to find out is to go talk to\\nthem\\nIt's amazing how challenging that can be sometimes though\\nBefore we dive into some more specifics around, you know, data-centric approaches\\nand whatnot\\n\", \"Overall, do you have a sense of where you think there are real competitive\\nadvantages in A\\nI\\nfor businesses? I sense that, you know, maybe to some degree, it looks very similar to\\nhow it's historically looked or where advantages or value opportunities already exist\\nwith customers\\nIs that kind of your position? Are there nuances to that? Yeah, I mean, like one use\\ncase that jumps out to me today for enterprise for large businesses is, you know, one\\nthing we like to do is we like to go and do events for people and we'll go and we'll\\nopen up their web page and we'll show that their web page chatbot is just absolutely\\ngarbage, right? We'll ask it a question\\nWe'll be like, hey, can you answer this simple question of this policy that is clearly on\\nyour website and I can find on the other page? And it literally can't answer the\\nquestion\\nAnd you're like, what's the point of this thing? And the answer is baked into whatever\\nsort of website creation thing that you used\\nAnd that's sort of the stats of these chatbots\\nYeah\\nSo it always goes back to chatbots, right? So, you know, it's like the, what you can do\\ntoday is you can build a simple retrieval augment generation system\\nYou can web scrape your own website and you can build this thing independent of\\nyour website as a question answering AI that returns a coherent answer and also\\nreturns you specific links to exact reference information and documentation where you\\nfound it\\nNow, this is sort of level one\\nBut what you want to think about is when your customer asks a question into a live\\nchat, what's the person actually doing? They're coming in and they're saying, well, let\\nme see, what exactly have we done with Evan before? Let me look and see what his\\nentire, what products has he bought for us? How many times he's called support?\\nWhat's Evan in his general demeanor towards us like? How should we be engaging\\nwith him? How could we potentially upsell or what could we potentially do right now to\\nmake his life a little easier or better? Like, there's a complex sort of meta problem\\namongst all possible Evan's and Greg's that people have ever had in their customer\\nbase, right? And the thing is like, if you don't go and you don't start building your own\\nsolution to this today, what's going to happen is\\n\"]\n",
            "[\"All right, hey everyone, welcome back to Coding Temple's Agile Leaders\\nWe help product and tech leaders execute and innovate in these rapidly changing\\ntimes with more confidence and velocity\\nI'm your host, Evan Shye\\nToday we are joined by my friend, Greg Lachnane, the co-founder and CEO of AI\\nMaker Space, where him and his incredible team are building the world's leading\\ncommunity for building production LLM applications\\nSo this episode is for the technologists out there looking to push the bleeding edge of\\nAI in their organization\\nThank you so much for being here, Greg\\nYeah, thanks for having me, Evan\\nIt's awesome to be here with you\\nWell, I have the pleasure of knowing a little bit about your background and how\\nimpressive it is and why you are my go-to source for everything related to AI, but\\nmaybe you can share a little bit about your journey with the audience here\\nYeah, you know, in 2015, I graduated with my PhD\\nIt was an optimization at the time\\nAnd part of the reason I even got i\", \", but\\nmaybe you can share a little bit about your journey with the audience here\\nYeah, you know, in 2015, I graduated with my PhD\\nIt was an optimization at the time\\nAnd part of the reason I even got it was because I kind of loved teaching\\nAnd I started doing that as an undergrad\\nSo quickly kind of came out of school, got into government contracting, consulting and\\nstarted work with teams to commercialize tech\\nAnd that kind of led me into liking the startup vibe more than the big companies\\nAnd I found it was very hard to make money with research\\nAnd even though I started to do some consulting outside of government contracting\\nwith actual startups, I found it was really still hard to make money with AI at the time,\\n16, 17, 18\\nAnd I started doing a lot of sort of just research for the CTO and you're kind of taking\\nthis work that you do and you're thrown it over the wall of the engineering team and it\\noften dies on the mind\\nYou know, this kind of pushed me more and more towards trying to g\", \" you're kind of taking\\nthis work that you do and you're thrown it over the wall of the engineering team and it\\noften dies on the mind\\nYou know, this kind of pushed me more and more towards trying to get inside and\\nbuild something with a team towards product management\\nSo I kind of went and I went to entrepreneurship school, dabbled in some startups that\\nweren't mind all along I'm teaching and then COVID hits\\nAnd I realized like, man, online teaching and learning is like, this is like the future\\nI like, I have got to get into this\\nI've always loved teaching\\nIt's never really paid, but I got the feeling at the time this is what I should be focused\\non\\n2020 actually take a full time job teaching\\nSo I'm teaching five days a week\\nI'm trying to become like the best at online teaching and learning\\nAnd you know, it was a big opportunity because still most people have never been to\\na Zoom room\\nThat's like really, really well run\\nIt's not like a thing that people have experienced\\n\", \"\\nAnd you know, it was a big opportunity because still most people have never been to\\na Zoom room\\nThat's like really, really well run\\nIt's not like a thing that people have experienced\\n\", \"But it can be done\\nAnd you know, this is something I've been working on for the last four or five years\\nI tried to launch a course back then teaching people 3D printing\\nIt was a disaster\\nI don't really know what I was doing\\nHeaded out to Silicon Valley to sort of learn startups, learn the industry of EdTech,\\nunderstand boot camps\\nIt's kind of got me into a role at the company called fourth brain, which is very close to\\ndeep learning AI and got me kind of close to a lot of people that are kind of at the top\\nof the industry\\nI looked around and I realized like this is what I want to be doing building these boot\\ncamps, but this sort of VC product, VC backed, EdTech boot camp business model\\nIt's not quite right\\nAnd so, you know, after Chad GBT came out, 2023, I realized, man, this is the year\\nI want to do this a little bit better than I've ever seen anybody do it\\nThis kind of led to what AI maker space has become today\\nSo we're building boot camps out on the edge of what's possible with ope\", \" want to do this a little bit better than I've ever seen anybody do it\\nThis kind of led to what AI maker space has become today\\nSo we're building boot camps out on the edge of what's possible with open source\\nAnd that's LLM today in production\\nI love it, man\\nI knew there were some similarities in our journey, but I didn't quite appreciate how\\nmuch\\nI guess I've been an entrepreneur my entire career, but did some time in an\\nacademia, a few of us in a PhD program and was publishing research and realizing\\nhow far of a distance or golf there was between the work we were publishing and the\\nimpact I was having on people's lives and ended up starting trying to do skill\\ndevelopment, building applications to deliver to that skill development, to make a\\nbigger impact in people's lives\\nAnd then, you know, a lot of philosophical alignment in terms of how can we do that\\nbetter and ultimately brought both of us here, I think\\nWere there any skills that were kind of most transferable from that past lif\", \"now, a lot of philosophical alignment in terms of how can we do that\\nbetter and ultimately brought both of us here, I think\\nWere there any skills that were kind of most transferable from that past life into more\\nof the operator seat, product leader seat? Yeah, I mean, you know, I think when I look\\nacross all of it, it's kind of like this willingness to sort of like attack one thing as hard as\\nyou can at each period\\nSo it kind of is like resilience is number one\\nIt's kind of like cookie cutter thing, but like, you know, like I was deeply under\\nemployed for long stretches, you know, throughout this journey\\nAnd it's just part of like continuing to just smash the grind\\nBut each sort of skill I learned a long way, like doing research, very important if you're\\ngoing to do consult things, right? And then building a startup, actually the way you\\nbuild it out to begin with and find product market fit and figure out what you should be\\nbuilding is kind of through consulting\\nAnd so like, you know,\", 'And then building a startup, actually the way you\\nbuild it out to begin with and find product market fit and figure out what you should be\\nbuilding is kind of through consulting\\nAnd so like, you know, each of these things kind of stacks on each other\\nAnd then it was very, very helpful to go sort of get the broad perspective of\\nentrepreneurship school, dabble a little bit of this and that\\n', \"And then as a CEO, I'm finding I go back to some of that, you know, okay, I have a\\nCFO day\\nI got to go pick up how to actually do the balance sheet stuff\\nOkay, I have this kind of day\\nAnd, you know, I think that that's been, it's just kind of all come together because the\\nstartup CEO is kind of an everything job\\nSo you kind of have to stack it one piece at a time\\nAmen, man\\nEven something as seemingly singularly constrained to science or research, but just\\nthe scientific method or running experiments appropriately and developing\\nhypotheses\\nAnd it always doesn't have to be this like perfectly elaborate experiment, but even just\\nthinking in ways where you can actually test hypotheses or expose where you're\\nwrong\\nI think is a useful thing for a lot of entrepreneurs who are trying to\\nThat's right\\nAnd I think like I've talked to, you know, mentors of mine, whatever, it's like this idea\\nthat what is your hypothesis? Because the thing about business is like, you have to\\nfigure out what's true \", \"ht\\nAnd I think like I've talked to, you know, mentors of mine, whatever, it's like this idea\\nthat what is your hypothesis? Because the thing about business is like, you have to\\nfigure out what's true about your customers, you have to figure out what's true about\\nwhat's going wrong in your company\\nAnd it's like, it's like the opposite of sort of like getting emotional about it and whatever\\nyou feel about it\\nAnd so you've got to be able to say, okay, and the decision making framework of the\\nhypothesis is very useful because otherwise like if you're trying to think about\\neverything and how it engages in interacts, like you can't make any decisions\\nIt's like this hypothesis, this is how I'm going to test it\\nYou know, it's very, very, it's exactly that in business\\nYeah, that you have to have a scientific method, you know, let's get to the truth as fast\\nas possible because we're going to get there one way or another and like that's not\\npay a toll for the fee tour, you know\\nSo kind of leaning\", \"scientific method, you know, let's get to the truth as fast\\nas possible because we're going to get there one way or another and like that's not\\npay a toll for the fee tour, you know\\nSo kind of leaning back on, I guess some of your consulting work and then now what\\nyou're seeing with technologists and technical leaders inside enterprises, you know,\\nobviously a lot of organizations, most probably organizations are starting to really look\\nat AI and recognize that there are meaningful implications that this is going to have on\\nour business\\nBut what do we ultimately do about it? What is the strategy? How do we actualize that\\nstrategy and create value for the organization? Is there a common thread or a primary\\nset of challenges that you see technology leaders face when implementing AI\\nstrategies in their organization? Yeah, I mean, I think that you have to sort of break\\ndown the industry into its component parts and you have to break down the\\ntechnology at the same time\\nSo, you know, in indu\", \" in their organization? Yeah, I mean, I think that you have to sort of break\\ndown the industry into its component parts and you have to break down the\\ntechnology at the same time\\nSo, you know, in industry, you're going to prototype things and then you're going to\\nput them into production\\nOn the technology side, we really want to kind of differentiate between AI sort of\\nclassical machine learning, deep learning and then this sort of generative AI that we're\\n\", \"talking about when we talk about large language models\\nOf course, there are many, many fine lines there, but from a what you should be\\nbuilding for your customers perspective, you know, you want to understand, okay, top\\nlevel, yes, I need to go from prototype to production\\nYes, I need to understand AI versus generative AI\\nBut you know what your customers want and what is going to make their lives easier\\nAnd like part of the thing is, part of the dirty little secret is like, well, most products\\ntoday that are built do not actually require AI\\nAnd you know, of the ones that do require AI, most of them do not require generative\\nAI\\nSo you end up when you go and you take it, I'm only going to create business value\\nfrom my customers perspective\\nYou end up kind of taking this unsexy approach of saying, well, maybe I'll just do sort\\nof classic product management\\nMaybe I'll do more classical AI product management\\nBut you know, the board's asking about LLAMs\\nEverybody wants to know what we're doi\", \"ying, well, maybe I'll just do sort\\nof classic product management\\nMaybe I'll do more classical AI product management\\nBut you know, the board's asking about LLAMs\\nEverybody wants to know what we're doing with LLAMs\\nChat GBT came out\\nEverybody's freaking out\\nWhat are we doing about it? It's important to have something there\\nAnd it's important to start moving down this prototyping to production pathway\\nAnd so this is where I'll sort of leave the classical AI aside and talk about generative\\nbecause that's what people want to hear about today\\nI think one of the things is there are companies that are good at prototyping already\\nThey're great at it\\nAnd they're sitting there and they're like, we got these prototypes\\nWe're dangling the candy in front of people that are in the company\\nThey're like, man, what are we waiting for? Let's push these things to production and\\nscale them out\\nThese are amazing applications\\nAnd there's a real hang up there in production\\nSo these are the financial industri\", \"man, what are we waiting for? Let's push these things to production and\\nscale them out\\nThese are amazing applications\\nAnd there's a real hang up there in production\\nSo these are the financial industries, this is the insurance industry\\nThis is these are the guys that have an all digital product\\nSo it's all digital\\nIt's all about the data\\nIt always has been, you know, quants are the OG, ML and AI people\\nMaking money off and making money has always kind of led the way here\\nSo these industries that build products based on that idea are still very much leading\\nthe way\\nAnd so, you know, when I talk to folks from industries like that, what you end up\\nhearing is going to appear\\nWell, a lot of these challenges of going to production, the infrastructure for LLMs in\\nproduction is different than the infrastructure for AI's in production\\nIt's classical AI in production\\nAnd by the nature of the large in large language models\\n\", \"nfrastructure for AI's in production\\nIt's classical AI in production\\nAnd by the nature of the large in large language models\\n\", \"And so you end up like having to figure out how to get new tools\\nAnd there are a lot of these open source edge tools that, you know, they're not well\\nsupported\\nSo in production, right, if something breaks at 1, 2, 3, 4 in the morning, who are you\\ngoing to call to make sure that you can fix it? And if the answer is, I don't have\\nanybody to call, well, we don't want to go to production\\nAnd this is a very important gap right now in the industry that we're going to continue\\nto try to create some value for folks in that space is one of, is one of our key strategic\\ngoals of this year\\nSo because we believe that's the open source edge\\nNow, most people are not there, all right? Most people are back in the productions in\\nthe prototyping phase\\nAnd in the prototyping phase, you have to sort of decide what should I be building?\\nWhy? How am I going to leverage tools like prompt engineering, like fine tuning, like\\nretrieval augmented generation, bragg? If you can't sort of intelligently even speak\\nab\", \"what should I be building?\\nWhy? How am I going to leverage tools like prompt engineering, like fine tuning, like\\nretrieval augmented generation, bragg? If you can't sort of intelligently even speak\\nabout these topics, let alone how they relate to one another and how they come\\ntogether holistically to create an app that has human level performance\\nThat's aligned with your customers\\nThat's giving a great experience\\nThat's not going to get you in trouble\\nAnd you're not very good at prototyping yet\\nAnd you should be spending your energies and your focus there\\nSo I think what you have to do is you have to look across your organization\\nYou have to be real honest about how mature are we from a technological standpoint\\nSome industries are just less mature, manufacturing, defense\\nThey tend to move slower and that's OK\\nSome other industries feel the heat of competition, the insurance, right? The financial,\\nthey're like, if we don't get on this, we're out of business\\nSo if you have to look at you\", \"slower and that's OK\\nSome other industries feel the heat of competition, the insurance, right? The financial,\\nthey're like, if we don't get on this, we're out of business\\nSo if you have to look at your industry, you have to look at your actual executive team\\nand the capabilities you have from a data science and machine learning perspective\\nnow\\nAnd you have to start building on that wherever you are\\nAnd whatever that looks like is going to be different for your particular situation\\nBut it always starts with proof concepts and prototypes\\nIt always moves into production\\nAnd you're always going to have to make that differentiation between classical\\nmachine learning deep learning and generative AI and no AI at all\\nSo it's tough to answer the question in general\\nBut that's my best right there\\nIt's a very, very useful framing and mental model that helps kind of bifurcate and\\norganize the different contexts that businesses or maybe the different phases that\\nbusinesses are ultimately in\\nAnd the\", \"'s a very, very useful framing and mental model that helps kind of bifurcate and\\norganize the different contexts that businesses or maybe the different phases that\\nbusinesses are ultimately in\\nAnd they're interesting points in both elements\\nI guess let's start with the\\n\", \"Well, actually, do you have a general sense or pulse, at least even anecdotally just\\nbased on your experience? Where do the majority of businesses fall right now? In the\\nproduction phase or the prototyping phase? Bass majority of businesses are stuck in\\nprototyping\\nVery, very few businesses that I've spoken to are actually out like\\nThey're like, yeah, yeah, we get it\\nWe understand how to use all the latest and greatest tools\\nWe're building that\\nOur people understand it\\nThe thing is we have these sort of like\\nOther infrastructure, security, whatever issues that are halting me now from creating\\nmassive value with these tools tomorrow\\nRight? And so that's the edge\\nMost people are somewhere getting started\\nOne, two, three POCs, prototypes\\nYou really have to sort of maybe get five or ten that actually really worked and you\\nknow you want to go to production with\\nSo it's kind of a long road from starting POCs to being ready to rock\\nTotally, totally get that\\nWe'll spend a meaningful amount of \", \"ctually really worked and you\\nknow you want to go to production with\\nSo it's kind of a long road from starting POCs to being ready to rock\\nTotally, totally get that\\nWe'll spend a meaningful amount of time in that kind of earlier phase and how you go\\nabout approaching it to hopefully create as much downstream value for customers as\\npossible\\nAlthough I will say that you really nicely elucidated some seemingly inevitable\\nchallenges that companies will face on the production side of it, particularly as it\\nrelates to skill gaps and capacity planning and all of that to ensure that they're not only\\nable to launch it in production but maintain it and continue to iterate on it\\nYeah, yeah\\nThe iteration has a whole other piece\\nYeah, yeah, yeah\\nI'm glad I bet\\nOkay, so we're in the earlier part of the journey as a company, you know, really\\nevaluating\\nOkay, we know, well, we have some early hypotheses about how we can create value\\nfor customers\\nI guess are there the frameworks with which you would a\", \"journey as a company, you know, really\\nevaluating\\nOkay, we know, well, we have some early hypotheses about how we can create value\\nfor customers\\nI guess are there the frameworks with which you would advise product leaders or\\ntechnical leaders to utilize out of the gate to ensure that they are consistently orienting\\naround customer value and not kind of getting distracted by shiny objects? Yeah, I\\nmean, I mean, I would just, I would start with, you know, your last quarter, your last\\nyear's strategy and, you know, it's like, well, what are some of the initiatives that you\\nhave on there that could potentially be augmented with some of these newer\\ntechnologies? You know, like that, that, that sort of easiest, lowest hanging fruit\\nAnd then one of the other things is, I mean, that I recommend to people is like, go\\naround to, you know, your, your functional department head, your functions, your\\ndepartments, whatever\\nYou, you are, and you ask people to leave them\\n\", ' people is like, go\\naround to, you know, your, your functional department head, your functions, your\\ndepartments, whatever\\nYou, you are, and you ask people to leave them\\n', \"It's like, what are some things that your people like complain about having to do all the\\ntime that are pretty monotonous? Like, what are the things that, you know, and you're\\noften like, it's a customer support, right? It's a, it's the same question I'm answering\\nover and over\\nIt's the same freaking pipe I'm fixing 10,000 times\\nAnd the different maintenance person has to figure it out exactly the same way, even\\nthough it's already been done 15 times before\\nIt's like, where are you not transferring that sort of, that sort of learned experience and\\nknowledge to the next person, the next person, the next person? And how can you\\nsort of automate that? Or what questions is HR getting on, you know, policies\\nconstantly, right? You sort of question answering systems or great sort of framework\\nand mental model of use\\nLike, where are people asking questions that you get the same answer over and over,\\nright? And, and, you know, that, that to me is probably the place to start is, what's\\nbothering\", \" mental model of use\\nLike, where are people asking questions that you get the same answer over and over,\\nright? And, and, you know, that, that to me is probably the place to start is, what's\\nbothering people about what they have to spend time on? That's sort of an internal\\napplication thing\\nSo questions are you answering for customers over and over and over? That's sort of\\nthe number one external application thing\\nAnd then, you know, look in your own strategy, maybe you can start there and see\\nwhat you can come up with\\nI love that\\nThe, the internal focus first feels like to your point, lowering fruit, safer, more reliable\\nI mean, by definition, you can talk directly to the customer, the customer is part of your\\norganization\\nSo probably a safer space to be\\nYou get, you capture some fast wins and you start to develop more confidence in the\\nmuscle and in the technology and you could probably build on that to some degree\\nYeah\\nYeah\\nAnd, and I think like one of the classic ones, even from cl\", \"s and you start to develop more confidence in the\\nmuscle and in the technology and you could probably build on that to some degree\\nYeah\\nYeah\\nAnd, and I think like one of the classic ones, even from classic A\\nI\\nwas like the auto quoting sales tool, right? It's like, why are we, why are we still\\nmanually quoting people? Like, but can you actually build something that your sales\\nteam wants to use is the real question, right? Not that you're like forcing them by\\nhooking cropped to sort of like, no, you have to pick this up otherwise\\nYeah\\nAnd so are you actually building things that people want? It's as much either testing\\nsite too\\nIt always matters, man\\nIs this something people actually want? And the best way to find out is to go talk to\\nthem\\nIt's amazing how challenging that can be sometimes though\\nBefore we dive into some more specifics around, you know, data-centric approaches\\nand whatnot\\n\", 'though\\nBefore we dive into some more specifics around, you know, data-centric approaches\\nand whatnot\\n', \"Overall, do you have a sense of where you think there are real competitive\\nadvantages in A\\nI\\nfor businesses? I sense that, you know, maybe to some degree, it looks very similar to\\nhow it's historically looked or where advantages or value opportunities already exist\\nwith customers\\nIs that kind of your position? Are there nuances to that? Yeah, I mean, like one use\\ncase that jumps out to me today for enterprise for large businesses is, you know, one\\nthing we like to do is we like to go and do events for people and we'll go and we'll\\nopen up their web page and we'll show that their web page chatbot is just absolutely\\ngarbage, right? We'll ask it a question\\nWe'll be like, hey, can you answer this simple question of this policy that is clearly on\\nyour website and I can find on the other page? And it literally can't answer the\\nquestion\\nAnd you're like, what's the point of this thing? And the answer is baked into whatever\\nsort of website creation thing that you used\\nAnd that's sort of the sta\", \"nd it literally can't answer the\\nquestion\\nAnd you're like, what's the point of this thing? And the answer is baked into whatever\\nsort of website creation thing that you used\\nAnd that's sort of the stats of these chatbots\\nYeah\\nSo it always goes back to chatbots, right? So, you know, it's like the, what you can do\\ntoday is you can build a simple retrieval augment generation system\\nYou can web scrape your own website and you can build this thing independent of\\nyour website as a question answering AI that returns a coherent answer and also\\nreturns you specific links to exact reference information and documentation where you\\nfound it\\nNow, this is sort of level one\\nBut what you want to think about is when your customer asks a question into a live\\nchat, what's the person actually doing? They're coming in and they're saying, well, let\\nme see, what exactly have we done with Evan before? Let me look and see what his\\nentire, what products has he bought for us? How many times he's called support?\\n\", \"oming in and they're saying, well, let\\nme see, what exactly have we done with Evan before? Let me look and see what his\\nentire, what products has he bought for us? How many times he's called support?\\nWhat's Evan in his general demeanor towards us like? How should we be engaging\\nwith him? How could we potentially upsell or what could we potentially do right now to\\nmake his life a little easier or better? Like, there's a complex sort of meta problem\\namongst all possible Evan's and Greg's that people have ever had in their customer\\nbase, right? And the thing is like, if you don't go and you don't start building your own\\nsolution to this today, what's going to happen is\\n\"]\n"
          ]
        }
      ],
      "source": [
        "# Lets load the pdf file and create chunks of text from it\n",
        "from PyPDF2 import PdfReader\n",
        "\n",
        "pdfDocuments = []\n",
        "# Load the PDF file\n",
        "reader = PdfReader(\"data/transcript.pdf\")\n",
        "\n",
        "# Extract text from all pages\n",
        "for page in reader.pages:\n",
        "    pdfDocuments.append(page.extract_text())\n",
        "\n",
        "# Lets peek into the pdfDocuments\n",
        "print(pdfDocuments)\n",
        "\n",
        "text_splitter = CharacterTextSplitter()\n",
        "split_pdf_documents = text_splitter.split_texts(pdfDocuments)\n",
        "split_pdf_documents[0:1]\n",
        "len(split_pdf_documents)\n",
        "print(split_pdf_documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The speaker is Evan Shye, and the guest is Greg Lachnane, the co-founder and CEO of AI Maker Space.\n",
            "Greg is trying to provide insights into building production LLM (Large Language Model) applications and the challenges associated with using open source edge tools in production. He emphasizes the importance of having reliable support for these tools, particularly in critical situations, and aims to create value for those in the prototyping phase of development by discussing strategies like prompt engineering and fine-tuning.\n"
          ]
        }
      ],
      "source": [
        "# Lets create a vector database from the split pdf documents\n",
        "# Lets add metadata to the vector database\n",
        "metadata = [{\"source\": \"greg-audio.wav\"}]\n",
        "vector_db = VectorDatabase()\n",
        "vector_db = asyncio.run(vector_db.abuild_from_list(split_pdf_documents))\n",
        "\n",
        "# Lets create a new pipeline\n",
        "retrieval_augmented_qa_pipeline = RetrievalAugmentedQAPipeline(\n",
        "    vector_db_retriever=vector_db,\n",
        "    llm=chat_openai\n",
        ")\n",
        "\n",
        "# Lets use the RAG pipeline to answer questions about the transcript\n",
        "response = retrieval_augmented_qa_pipeline.run_pipeline(\"Who is the speaker and guest?\")\n",
        "print(response['response'])\n",
        "response = retrieval_augmented_qa_pipeline.run_pipeline(\"What is Greg trying to provide insights into?\")\n",
        "print(response['response'])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "orig_nbformat": 4,
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1ce393d9afcf427d9d352259c5d32678": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e6efd99f7d346e485b002fb0fa85cc7",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3dfb67c39958461da6071e4c19c3fa41",
            "value": 1
          }
        },
        "3a4ba348cb004f8ab7b2b1395539c81b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2ea5009dd16442cb5d8a0ac468e50a8",
            "placeholder": "​",
            "style": "IPY_MODEL_5f00135fe1044051a50ee5e841cbb8e3",
            "value": "0.018 MB of 0.018 MB uploaded\r"
          }
        },
        "3dfb67c39958461da6071e4c19c3fa41": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4e6efd99f7d346e485b002fb0fa85cc7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56a8e24025594e5e9ff3b8581c344691": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f00135fe1044051a50ee5e841cbb8e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb904e05ece143c79ecc4f20de482f45": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3a4ba348cb004f8ab7b2b1395539c81b",
              "IPY_MODEL_1ce393d9afcf427d9d352259c5d32678"
            ],
            "layout": "IPY_MODEL_56a8e24025594e5e9ff3b8581c344691"
          }
        },
        "d2ea5009dd16442cb5d8a0ac468e50a8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
